{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c7b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ AutoMM ÂØ¶‰ΩúÁâàÊú¨ÔºöÂúñÂÉè + Ê®ôÈ°å + ÁµêÊßãÊ¨Ñ‰Ωç È†êÊ∏¨ËßÄÁúãÊï∏\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcbb7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Ë®≠ÂÆöÊ™îÊ°àË∑ØÂæë ===\n",
    "data_dir = \"C:/Users/user/Desktop/Á¢©‰∏Ä‰∏ã/Ë≥áÊñôÊé¢Âãò/HW/113-2-data-mining-homework-2\"  # üîÅ ‰øÆÊîπÊàê‰Ω†ÁöÑË≥áÊñôÂ§æ‰ΩçÁΩÆ\n",
    "train_csv = os.path.join(data_dir, \"train_data.csv\")  # È†êËôïÁêÜÂæåÁöÑË≥áÊñô\n",
    "test_json_path = os.path.join(data_dir, \"test_data.json\")\n",
    "# ‚úÖ ‰Ω†ÈúÄË¶ÅÂÖàÂ∞á train_data.json + train_label.csv merge Êàê‰∏Ä‰ªΩ train_data.csvÔºå‰∏¶ÂåÖÂê´ÂúñÁâáË∑ØÂæë\n",
    "# ‚úÖ Ê¨Ñ‰ΩçÈúÄÂåÖÂê´ÔºöPid, Title, Category, Subcategory, Postdate, ImageÔºàË∑ØÂæëÔºâ, labelÔºàËßÄÁúãÊï∏ÔºâÁ≠âÊ¨Ñ‰Ωç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "720d1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. ËÆÄÂèñË®ìÁ∑¥Ë≥áÊñô ===\n",
    "df = pd.read_csv(train_csv)\n",
    "df[\"image\"] = df[\"image\"].apply(lambda x: os.path.abspath(os.path.join(data_dir, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "316061da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. È°çÂ§ñÁµêÊßãÁâπÂæµ ===\n",
    "df[\"title_length\"] = df[\"Title\"].astype(str).str.len()\n",
    "df[\"is_weekend\"] = df[\"weekday\"] >= 5\n",
    "df[\"hour_bin\"] = pd.cut(df[\"hour\"], bins=[-1, 6, 12, 18, 24], labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ded12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. log(label) ËôïÁêÜ ===\n",
    "df[\"label\"] = np.log1p(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb9cf7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250517_121359\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.5.1+cu118\n",
      "CUDA Version:       11.8\n",
      "Memory Avail:       10.08 GB / 31.24 GB (32.3%)\n",
      "Disk Space Avail:   75.48 GB / 449.47 GB (16.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. ‚ú®‚ú®‚ú®\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir c:\\Users\\user\\Desktop\\Á¢©‰∏Ä‰∏ã\\Ë≥áÊñôÊé¢Âãò\\HW\\113-2-data-mining-homework-2\\AutogluonModels\\ag-20250517_121359\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 110 M  | train\n",
      "1 | validation_metric | MeanSquaredError    | 0      | train\n",
      "2 | loss_func         | MSELoss             | 0      | train\n",
      "------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.791   Total estimated model params size (MB)\n",
      "309       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:07<01:07, 12.50it/s]                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 52: 'val_rmse' reached 0.98083 (best 0.98083), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=0-step=52.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:19<00:00, 12.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 106: 'val_rmse' reached 0.89890 (best 0.89890), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=0-step=106.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:05<01:05, 12.88it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 158: 'val_rmse' reached 0.87576 (best 0.87576), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=1-step=158.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:23<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 212: 'val_rmse' reached 0.86288 (best 0.86288), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=1-step=212.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:05<01:05, 12.86it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 264: 'val_rmse' reached 0.83190 (best 0.83190), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=2-step=264.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:21<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 318: 'val_rmse' reached 0.82706 (best 0.82706), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=2-step=318.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:06<01:06, 12.65it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 370: 'val_rmse' reached 0.78212 (best 0.78212), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=3-step=370.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:23<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 424: 'val_rmse' reached 0.79194 (best 0.78212), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=3-step=424.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:06<01:06, 12.67it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 476: 'val_rmse' reached 0.78423 (best 0.78212), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=4-step=476.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:25<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 530: 'val_rmse' reached 0.78167 (best 0.78167), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=4-step=530.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:11<01:11, 11.78it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 582: 'val_rmse' reached 0.78123 (best 0.78123), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=5-step=582.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:33<00:00, 10.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 636: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:11<01:11, 11.84it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 688: 'val_rmse' reached 0.77693 (best 0.77693), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=6-step=688.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:33<00:00, 10.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 742: 'val_rmse' reached 0.75964 (best 0.75964), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=6-step=742.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:10<01:10, 11.93it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 794: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:25<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 848: 'val_rmse' reached 0.76645 (best 0.75964), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=7-step=848.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:09<01:09, 12.07it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 900: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:25<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 954: 'val_rmse' reached 0.77202 (best 0.75964), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=8-step=954.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:09<01:09, 12.23it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1006: 'val_rmse' reached 0.76481 (best 0.75964), saving model to 'C:\\\\Users\\\\user\\\\Desktop\\\\Á¢©‰∏Ä‰∏ã\\\\Ë≥áÊñôÊé¢Âãò\\\\HW\\\\113-2-data-mining-homework-2\\\\AutogluonModels\\\\ag-20250517_121359\\\\epoch=9-step=1006.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:31<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1060: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:08<01:08, 12.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1112: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1688/1688 [02:23<00:00, 11.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1166: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 844/1688 [01:09<01:09, 12.14it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1218: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1089/1688 [01:33<00:51, 11.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 0:30:00. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1090/1688 [01:38<00:54, 11.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1234: 'val_rmse' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1090/1688 [01:44<00:57, 10.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 23.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:01<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:01<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. üéâüéâüéâ\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"c:\\Users\\user\\Desktop\\Á¢©‰∏Ä‰∏ã\\Ë≥áÊñôÊé¢Âãò\\HW\\113-2-data-mining-homework-2\\AutogluonModels\\ag-20250517_121359\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x231c2412a50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 3. Âª∫Á´ã AutoMM Ê®°Âûã‰∏¶Ë®ìÁ∑¥ ===\n",
    "predictor = MultiModalPredictor(label=\"label\", problem_type=\"regression\")\n",
    "predictor.fit(\n",
    "    df,\n",
    "    time_limit=1800, # ÂèØË™øÊï¥\n",
    "    presets=\"high_quality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0edc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. ËôïÁêÜÊ∏¨Ë©¶Ë≥áÊñô ===\n",
    "with open(test_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df[\"image\"] = test_df[\"img_filepath\"].apply(lambda p: os.path.join(os.path.abspath(data_dir), p))\n",
    "test_df[\"Postdate\"] = pd.to_datetime(test_df[\"Postdate\"], unit=\"s\")\n",
    "test_df[\"weekday\"] = test_df[\"Postdate\"].dt.weekday\n",
    "test_df[\"hour\"] = test_df[\"Postdate\"].dt.hour\n",
    "test_df[\"title_length\"] = test_df[\"Title\"].astype(str).str.len()\n",
    "test_df[\"is_weekend\"] = test_df[\"weekday\"] >= 5\n",
    "test_df[\"hour_bin\"] = pd.cut(test_df[\"hour\"], bins=[-1, 6, 12, 18, 24], labels=[0,1,2,3])\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Pid\", \"Title\", \"Category\", \"Subcategory\",\n",
    "    \"weekday\", \"hour\", \"image\",\n",
    "    \"title_length\", \"is_weekend\", \"hour_bin\"\n",
    "]\n",
    "test_df = test_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ffe5967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:04<00:00, 35.57it/s]\n",
      "‚úÖ Â∑≤Ëº∏Âá∫ submission_automm_logfeat.csvÔºàÂê´ log(label) ËàáÈ°çÂ§ñÁâπÂæµÔºâ\n"
     ]
    }
   ],
   "source": [
    "# === 7. È†êÊ∏¨ + ÂèçËΩâ log(label) + Ëº∏Âá∫ÁµêÊûú ===\n",
    "preds_log = predictor.predict(test_df)\n",
    "preds = np.expm1(preds_log)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Pid\": test_df[\"Pid\"],\n",
    "    \"label\": preds\n",
    "})\n",
    "submission.to_csv(\"submission_automm_logfeat.csv\", index=False)\n",
    "print(\"‚úÖ Â∑≤Ëº∏Âá∫ submission_automm_logfeat.csvÔºàÂê´ log(label) ËàáÈ°çÂ§ñÁâπÂæµÔºâ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
